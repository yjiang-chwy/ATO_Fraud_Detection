{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b0ee3c21",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fee3d10",
   "metadata": {},
   "source": [
    "## Autoencoder Model Evaluation on Validation Set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c78b6803",
   "metadata": {},
   "source": [
    "Import Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba64a365",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import average_precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e25877e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load models\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model_autoencoder_p2_v1 = Autoencoder_p2_v1()\n",
    "model_autoencoder_p2_v1.load_state_dict(torch.load('model_name.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5796e3bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_autoencoder_p2_v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26dff017",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create validation dataloader\n",
    "val_loader = DataLoader(dataset=x_val, shuffle=False, batch_size=BATCH_SIZE)\n",
    "\n",
    "model_name = model_autoencoder_p2_v1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de22f70d",
   "metadata": {},
   "source": [
    "### Derive losses on validation dataset and true ato cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd0dd2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, val_loss = predict_batch(model_name, val_loader)\n",
    "_, ato_loss = predict(model_name, x_test_ato)\n",
    "_, all_loss = predict(model_name, x_test_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa76e4e6",
   "metadata": {},
   "source": [
    "Transform losses to numpy arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "957368e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_losses = np.array(val_loss)\n",
    "ato_losses = np.array(ato_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "414be044",
   "metadata": {},
   "source": [
    "Create labels for normal and ato cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5801d708",
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_label = np.zeros((normal_losses.shape), dtype=int)\n",
    "ato_label = np.ones((ato_loss.shape), dtype=int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeabc36c",
   "metadata": {},
   "source": [
    "Create true label and predictions scores for metrics calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d04d90c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = np.concatenate((normal_label, ato_label))\n",
    "y_score = np.concatenate((normal_losses, ato_losses))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5b9cb6b",
   "metadata": {},
   "source": [
    "### Derive false positive rate, true positive rate, thresholds and auc score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa7df326",
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = roc_curve(y_true, y_score)\n",
    "\n",
    "auc = auc(fpr, tpr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ab71727",
   "metadata": {},
   "source": [
    "Plot Roc curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0217548f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(1)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.plot(fpr, tpr, label='model_name (area = {:.3f})'.format(auc))\n",
    "\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC curve')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b6261dc",
   "metadata": {},
   "source": [
    "### Derive Recall, Precision, thresholds and F1-Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a3151d",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision , recall, thresholds_2 = precision_recall_curve(y_true, y_score)\n",
    "\n",
    "f1_score = 2*np.multiply(precision, recall)/(precision + recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d25e970",
   "metadata": {},
   "source": [
    "Plot F1-Scores against Thresholds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a67c13c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(2)\n",
    "plt.xlim(0, 10)\n",
    "plt.plot(thresholds_p2_v1, f1_p2_v1[:-1], label='model_p2_v1')\n",
    "plt.plot(thresholds_p2_v2, f1_p2_v2[:-1], label='model_p2_v2')\n",
    "plt.xlabel('Thresholds')\n",
    "plt.ylabel('F1-Score')\n",
    "plt.title('F1-Score')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cb32f60",
   "metadata": {},
   "source": [
    "## Model Performance on Test Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c65f0ad9",
   "metadata": {},
   "source": [
    "Read all fraud test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "999b5ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all types of frauds cases\n",
    "bucket_name = 'fraud-user-profile-sandbox/ATO_Features_V2'\n",
    "data_key = 'all_fraud_data.csv'\n",
    "data_location = 's3://{}/{}'.format(bucket_name, data_key)\n",
    "df_all_frauds = pd.read_csv(data_location)\n",
    "\n",
    "# ATO frauds cases\n",
    "data_key = 'ato_fraud_data.csv'\n",
    "data_location = 's3://{}/{}'.format(bucket_name, data_key)\n",
    "df_ato_frauds = pd.read_csv(data_location)\n",
    "\n",
    "\n",
    "df_ato_frauds.drop_duplicates(inplace=True)\n",
    "df_all_frauds.fillna(0, inplace=True)\n",
    "df_ato_frauds.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "474036a1",
   "metadata": {},
   "source": [
    "Read all test dataset for each month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36861541",
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_file_list = ['s3://fraud-user-profile-sandbox/ATO_Features_V2/dataset_FEB2021.csv.gz',\n",
    "                     's3://fraud-user-profile-sandbox/ATO_Features_V2/dataset_MAR2021.csv.gz',\n",
    "                     's3://fraud-user-profile-sandbox/ATO_Features_V2/dataset_APR2021.csv.gz',\n",
    "                     's3://fraud-user-profile-sandbox/ATO_Features_V2/dataset_MAY2021.csv.gz']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9f46c18",
   "metadata": {},
   "source": [
    "### Preprocess each months dataset and calculate losses for normal customer behaviors for each months."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b8147a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_normal_losses = []\n",
    "model_name = model_autoencoder_p2_v2\n",
    "for file in monthly_file_list:\n",
    "    # read monthly data\n",
    "    df_monthly = wr.s3.read_csv(path=file)\n",
    "    \n",
    "    # fill nulls with 0 and drop new features from the monthly data\n",
    "    df_monthly.fillna(0, inplace=True)\n",
    "    \n",
    "    \n",
    "    # remove the fraud cases from the monthly data\n",
    "    df_monthly = pd.merge(left=df_monthly, \n",
    "                  right=df_all_frauds[['CUSTOMER_ID','GA_SESSIONS_DATE']],\n",
    "                  on=['CUSTOMER_ID','GA_SESSIONS_DATE'], \n",
    "                  how='left',\n",
    "                  indicator=True)  \n",
    "    \n",
    "    df_monthly = df_monthly[df_monthly['_merge'] == 'left_only']\n",
    "    df_monthly = df_monthly.drop(columns='_merge')\n",
    "    \n",
    "    df_monthly = pd.merge(left=df_monthly, \n",
    "                  right=df_ato_frauds[['CUSTOMER_ID','GA_SESSIONS_DATE']],\n",
    "                  on=['CUSTOMER_ID','GA_SESSIONS_DATE'], \n",
    "                  how='left',\n",
    "                  indicator=True)  \n",
    "    \n",
    "    df_monthly = df_monthly[df_monthly['_merge'] == 'left_only']\n",
    "    df_monthly = df_monthly.drop(columns='_merge')\n",
    "    \n",
    "    # Drop Customer_id and Date\n",
    "    df_monthly = df_monthly.drop(columns=['CUSTOMER_ID','GA_SESSIONS_DATE'])\n",
    "    \n",
    "    # Standardize the monthly data\n",
    "    df_monthly = scaler_p2.transform(df_monthly)\n",
    "    \n",
    "    # Transfome nparray to torch.tensor\n",
    "    df_monthly = torch.from_numpy(df_monthly).float()\n",
    "    df_monthly.to(device)\n",
    "    \n",
    "    # Create the dataloader\n",
    "    monthly_loader = DataLoader(dataset=df_monthly, shuffle=False, batch_size=200000)\n",
    "    # Get prediction losses\n",
    "    _, normal_loss = predict_batch(model_name, monthly_loader)\n",
    "    monthly_normal_losses.append(normal_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f432e71",
   "metadata": {},
   "source": [
    "### Calculate losses on ATO fraud behaviors for each month."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d7a514",
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_ato_losses = []\n",
    "\n",
    "# Filter ATO cases in each month\n",
    "ato_feb = df_ato_frauds.loc[(df_ato_frauds['GA_SESSIONS_DATE'] >= '2021-02-01') \n",
    "                            & (df_ato_frauds['GA_SESSIONS_DATE'] <= '2021-02-28')]\n",
    "\n",
    "ato_mar = df_ato_frauds.loc[(df_ato_frauds['GA_SESSIONS_DATE'] >= '2021-03-01') \n",
    "                            & (df_ato_frauds['GA_SESSIONS_DATE'] <= '2021-03-31')]\n",
    "\n",
    "ato_apr = df_ato_frauds.loc[(df_ato_frauds['GA_SESSIONS_DATE'] >= '2021-04-01') \n",
    "                            & (df_ato_frauds['GA_SESSIONS_DATE'] <= '2021-04-30')]\n",
    "\n",
    "ato_may = df_ato_frauds.loc[(df_ato_frauds['GA_SESSIONS_DATE'] >= '2021-05-01') \n",
    "                            & (df_ato_frauds['GA_SESSIONS_DATE'] <= '2021-05-31')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae9728d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_ato_losses = []\n",
    "ato_monthly_files = [ato_feb, ato_mar, ato_apr, ato_may]\n",
    "\n",
    "for file in ato_monthly_files:\n",
    "    \n",
    "    file = file.drop(columns=['CUSTOMER_ID','GA_SESSIONS_DATE'])\n",
    "\n",
    "    file = scaler_p2.transform(file)\n",
    "    file = torch.from_numpy(file).float()\n",
    "    file.to(device)\n",
    "    \n",
    "    # Get prediction losses\n",
    "    _, ato_loss = predict(model_name, file)\n",
    "    monthly_ato_losses.append(ato_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdf7e99e",
   "metadata": {},
   "source": [
    "### Set up the threshold for decision boundary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c2ad26",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 4.3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c871d6ed",
   "metadata": {},
   "source": [
    "### Calculate the numbers of False Positives among each months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b0f15d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered = filter(lambda score: score >= threshold, monthly_normal_losses[0])\n",
    "fp_feb = len(list(filtered))\n",
    "\n",
    "filtered = filter(lambda score: score >= threshold, monthly_normal_losses[1])\n",
    "fp_mar = len(list(filtered))\n",
    "\n",
    "filtered = filter(lambda score: score >= threshold, monthly_normal_losses[2])\n",
    "fp_apr = len(list(filtered))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9022f3b3",
   "metadata": {},
   "source": [
    "### Calculate the numbers of True Positives among each months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1738e6fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "tp_feb = sum(l >= threshold for l in monthly_ato_losses[0])\n",
    "tp_mar = sum(l >= threshold for l in monthly_ato_losses[1])\n",
    "tp_apr = sum(l >= threshold for l in monthly_ato_losses[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0680c71b",
   "metadata": {},
   "source": [
    "# Evaluation of SVMs on validations sets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3bb8438",
   "metadata": {},
   "source": [
    "Calculate the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de680b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "SVM_rbf_pred_val = SVM_rbf_v1.predict(x_val)\n",
    "SVM_rbf_pred_test_ato = SVM_rbf_v1.predict(x_test_ato)\n",
    "SVM_rbf_pred_test_all = SVM_rbf_v1.predict(x_test_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d390dda",
   "metadata": {},
   "source": [
    "Calucalate the False negatives and True Positives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d2bf70e",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_error_val = SVM_rbf_pred_val[SVM_rbf_pred_val == -1].size\n",
    "n_pos_ato = SVM_rbf_pred_test_ato[SVM_rbf_pred_test_ato == -1].size\n",
    "n_pos_all = SVM_rbf_pred_test_all[SVM_rbf_pred_test_all == -1].size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ab2d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('False Positive Rate:', n_error_val/len(x_val))\n",
    "print('ATO Recall:', n_pos_ato/len(x_test_ato))\n",
    "print('All Recall:', n_pos_all/len(x_test_all))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e07662e",
   "metadata": {},
   "source": [
    "# Evaluation of Isolation Forests on validations sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d59c43a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_outliers = clf.predict(x_test_ato)\n",
    "\n",
    "y_pred_val = clf.predict(x_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a860e6c6",
   "metadata": {},
   "source": [
    "Calculate the true positives and false negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c68316f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tp = y_pred_outliers[y_pred_outliers == -1].size\n",
    "fp = y_pred_val[y_val == 1].size"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_amazonei_pytorch_latest_p36",
   "language": "python",
   "name": "conda_amazonei_pytorch_latest_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
