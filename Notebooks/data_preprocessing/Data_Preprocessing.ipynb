{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5af7b08e",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b66a5fe",
   "metadata": {},
   "source": [
    "Preprocessing the features set stored in S3 bucket for model training, including dropping unnecessary columns, filtering out frauds cases, and normalizations. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "163879d3",
   "metadata": {},
   "source": [
    "## Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a2f652",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install awswrangler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c98d9a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "import awswrangler as wr\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02fb61b2",
   "metadata": {},
   "source": [
    "## Read dataset from S3 Bucket"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "104f2697",
   "metadata": {},
   "source": [
    "Read the unlabelled enhanced dataset from 2020-12-06 to 2021-01-31 stored in s3 bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5116811e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train= pd.concat([wr.s3.read_csv(path=\"s3://fraud-user-profile-sandbox/ATO_Features_V2/dataset_DEC2020.csv.gz\"),\n",
    "                     wr.s3.read_csv(path=\"s3://fraud-user-profile-sandbox/ATO_Features_V2/dataset_JAN2021.csv.gz\")],\n",
    "                     ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b754255",
   "metadata": {},
   "source": [
    "Read all types of frauds cases and ato fraud cases stored in s3 bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "659eda11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all types of frauds cases\n",
    "bucket_name = 'fraud-user-profile-sandbox/ATO_Features_V2'\n",
    "data_key = 'all_fraud_data.csv'\n",
    "data_location = 's3://{}/{}'.format(bucket_name, data_key)\n",
    "df_all_frauds = pd.read_csv(data_location)\n",
    "\n",
    "# ATO frauds cases\n",
    "data_key = 'ato_fraud_data.csv'\n",
    "data_location = 's3://{}/{}'.format(bucket_name, data_key)\n",
    "df_ato_frauds = pd.read_csv(data_location)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50f099b4",
   "metadata": {},
   "source": [
    "fill the nulls with 0, which are due to lack of iOS/Android app data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d5b66f52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 33164907 entries, 0 to 33164906\n",
      "Data columns (total 38 columns):\n",
      " #   Column                                       Non-Null Count     Dtype  \n",
      "---  ------                                       --------------     -----  \n",
      " 0   CUSTOMER_ID                                  33164907 non-null  int64  \n",
      " 1   GA_SESSIONS_DATE                             33164907 non-null  object \n",
      " 2   DINSTINCT_PREV_CITY_CNTS                     33164907 non-null  int64  \n",
      " 3   DISTINCT_CITY_DAILY_CNTS                     33164907 non-null  int64  \n",
      " 4   DISTINCT_NEW_CITY_CNTS                       33164907 non-null  int64  \n",
      " 5   CITY_NOT_SET_FLAG                            33164907 non-null  int64  \n",
      " 6   DISTINCT_PREV_PRODUCTS_CLICKED_CNTS          33164907 non-null  int64  \n",
      " 7   DISTINCT_PREV_PRODUCTS_TYPE1_CLICKED_CNTS    33164907 non-null  int64  \n",
      " 8   DISTINCT_PREV_PRODUCTS_TYPE2_CLICKED_CNTS    33164907 non-null  int64  \n",
      " 9   DISTINCT_NEW_PRODUCT_CLICKED_CNTS            33164907 non-null  float64\n",
      " 10  DISTINCT_NEW_PRODUCT_TYPE1_CLICKED_CNTS      33164907 non-null  float64\n",
      " 11  DISTINCT_NEW_PRODUCT_TYPE2_CLICKED_CNTS      33164907 non-null  float64\n",
      " 12  DISTINCT_PREV_PRODUCTS_PURCHASED_CNT         33164907 non-null  int64  \n",
      " 13  DISTINCT_PREV_PRODUCTS_TYPE1_PURCHASED_CNTS  33164907 non-null  int64  \n",
      " 14  DISTINCT_PREV_PRODUCTS_TYPE2_PURCHASED_CNTS  33164907 non-null  int64  \n",
      " 15  DISTINCT_NEW_PRODUCT_PURCHASED_CNTS          33164907 non-null  float64\n",
      " 16  DISTINCT_NEW_PRODUCT_TYPE1_PURCHASED_CNTS    33164907 non-null  float64\n",
      " 17  DISTINCT_NEW_PRODUCT_TYPE2_PURCHASED_CNTS    33164907 non-null  float64\n",
      " 18  HAS_RESET_PASSWORD_FLAG                      33164907 non-null  float64\n",
      " 19  HAS_ADD_NEW_ADDRESS_FLAG                     33164907 non-null  float64\n",
      " 20  HAS_APPLIED_GIFTCARD_FLAG                    33164907 non-null  float64\n",
      " 21  HAS_CHANGE_AUTOSHIP_FREQUENCY_FLAG           33164907 non-null  float64\n",
      " 22  HAS_AUTOSHIP_SHIP_NOW_FLAG                   33164907 non-null  float64\n",
      " 23  HAS_ADD_PAYMENT_FLAG                         33164907 non-null  float64\n",
      " 24  TOTAL_NUM_ORDERS                             33164907 non-null  float64\n",
      " 25  NUM_ONETIME_ORDERS                           33164907 non-null  float64\n",
      " 26  DISTINCT_PRODUCT_ORDERED                     33164907 non-null  float64\n",
      " 27  DISTINCT_PRODUCT_ONETIME_ORDERED             33164907 non-null  float64\n",
      " 28  ONETIME_ORDER_QUANTITY                       33164907 non-null  float64\n",
      " 29  TOTAL_ORDER_QUANTITY                         33164907 non-null  float64\n",
      " 30  TOTAL_ORDER_PRICE                            33164907 non-null  float64\n",
      " 31  ONETIME_ORDER_PRICE                          33164907 non-null  float64\n",
      " 32  DISTINCT_PRODUCT_HIT                         33164907 non-null  int64  \n",
      " 33  TOTAL_PRODUCT_HIT                            33164907 non-null  int64  \n",
      " 34  DISTINCT_PRODUCT_CLICKED                     33164907 non-null  int64  \n",
      " 35  TOTAL_PRODUCT_CLICKED                        33164907 non-null  int64  \n",
      " 36  TOTAL_PAGES_VIEWED                           33164907 non-null  float64\n",
      " 37  DISTINCT_PAGES_VIEWED                        33164907 non-null  int64  \n",
      "dtypes: float64(21), int64(16), object(1)\n",
      "memory usage: 9.4+ GB\n"
     ]
    }
   ],
   "source": [
    "df_train.fillna(0, inplace=True)\n",
    "df_train.info(null_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c127145",
   "metadata": {},
   "source": [
    "fill the nulls in frauds dataframes with 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a873d6ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_frauds.fillna(0, inplace=True)\n",
    "df_ato_frauds.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd0fdf64",
   "metadata": {},
   "source": [
    "## Random Sampling "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f6b0ffb",
   "metadata": {},
   "source": [
    "The raw dataset from Dec 2020 to Jan 2021 contains 33,164,907 examples, which is more than enough more model training. In order to reduce training time, we randomly sample 20% of the raw dataset as our unprocessed training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dfe40409",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, df_train = train_test_split(df_train, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e86c175",
   "metadata": {},
   "source": [
    "## Remove frauds case in training set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf1789d",
   "metadata": {},
   "source": [
    "Previous dataset indicates highly imbalance of our dataset, so we employ unsupervised models, and train those models only on normal customers cases and here we remove all frauds cases and ato cases from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8462cea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge df_enhanced_features with all_fraud_cases\n",
    "df_train = pd.merge(left=df_train, \n",
    "                  right=df_all_frauds[['CUSTOMER_ID','GA_SESSIONS_DATE']],\n",
    "                  on=['CUSTOMER_ID','GA_SESSIONS_DATE'], \n",
    "                  how='left',\n",
    "                  indicator=True)  \n",
    "\n",
    "# Remove all the fraud cases from the merged dataframe\n",
    "df_train = df_train[df_train['_merge'] == 'left_only']\n",
    "df_train = df_train.drop(columns='_merge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c74c6b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Further remove the ato fraud cases from the merged dataframe\n",
    "df_train = pd.merge(left=df_train, \n",
    "                  right=df_ato_frauds[['CUSTOMER_ID','GA_SESSIONS_DATE']],\n",
    "                  on=['CUSTOMER_ID','GA_SESSIONS_DATE'], \n",
    "                  how='left',\n",
    "                  indicator=True)  \n",
    "\n",
    "df_train = df_train[df_train['_merge'] == 'left_only']\n",
    "df_train = df_train.drop(columns='_merge')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "710256e2",
   "metadata": {},
   "source": [
    "Drop 'Customer_ID' and 'GA_SESSIONS_DATE'   from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94aecc6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.drop(columns=['CUSTOMER_ID','GA_SESSIONS_DATE'])\n",
    "df_all_frauds = df_all_frauds.drop(columns=['CUSTOMER_ID','GA_SESSIONS_DATE'])\n",
    "df_ato_frauds = df_ato_frauds.drop(columns=['CUSTOMER_ID','GA_SESSIONS_DATE'])\n",
    "\n",
    "df_ato_frauds.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6502049",
   "metadata": {},
   "source": [
    "## Standadization of datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17a56d1d",
   "metadata": {},
   "source": [
    "Before We standardize the datasets, we take 5% smaples out of the training data as validation sets for model evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc22d765",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_val = train_test_split(x_train, test_size=0.05, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e76650e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_p2 = StandardScaler()\n",
    "scaler_p2.fit(x_train)\n",
    "\n",
    "x_train = scaler_p2.transform(x_train)\n",
    "\n",
    "x_test_ato = scaler_p2.transform(df_ato_frauds)\n",
    "x_test_all = scaler_p2.transform(df_all_frauds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d1355d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the size of different datasets\n",
    "print('Size of training example:', x_train.shape)\n",
    "print('Size of validation example:', x_val.shape)\n",
    "print('Size of all frauds example:', x_test_all.shape)\n",
    "print('Size of ato frauds example:', x_test_ato.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "037f8df7",
   "metadata": {},
   "source": [
    "## Now we have the datasets for model training and testing."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_amazonei_pytorch_latest_p36",
   "language": "python",
   "name": "conda_amazonei_pytorch_latest_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
